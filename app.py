import os
import sys
import threading
import queue
import asyncio
from flask import Flask, request, jsonify, Response, stream_with_context, send_file
from flask_cors import CORS

# --- è·¯å¾„å’Œé…ç½®åˆå§‹åŒ– ---
# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿èƒ½æ­£ç¡®å¯¼å…¥AgentCore
sys.path.append(os.path.abspath(os.path.dirname(__file__)))

try:
    from AgentCore.config import config
    from AgentCore.Society.market_monitor import MarketMonitorAgent
    from AgentCore.Society.market_trade import AgentManager
    from camel.models import ModelFactory
    from camel.types import ModelPlatformType, ModelType
except ImportError as e:
    print(f"âŒ å…³é”®æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("ğŸ–ï¸ è¯·ç¡®ä¿å·²åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ `pip install -r requirements.txt`")
    sys.exit(1)

# --- Flask åº”ç”¨åˆå§‹åŒ– ---
app = Flask(__name__)
# å…è®¸æ‰€æœ‰æ¥æºçš„è·¨åŸŸè¯·æ±‚ï¼Œæ–¹ä¾¿å‰ç«¯è°ƒè¯•
CORS(app)

# --- AIæ¨¡å‹å’ŒAgentåˆå§‹åŒ– ---
# åˆ›å»ºä¸€ä¸ªç»Ÿä¸€çš„AIæ¨¡å‹å®ä¾‹ï¼Œä¾›æ‰€æœ‰Agentä½¿ç”¨ï¼Œé¿å…èµ„æºæµªè´¹
print("ğŸ§  æ­£åœ¨åˆå§‹åŒ–AIæ¨¡å‹...")
try:
    # ä¼˜å…ˆå°è¯•ä½¿ç”¨ ModelScope Qwen æ¨¡å‹
    try:
        model = ModelFactory.create(
            model_platform=ModelPlatformType.MODELSCOPE,
            model_type='Qwen/Qwen2.5-72B-Instruct',
            model_config_dict={'temperature': 0.2},
            api_key='9d3aed4d-eca1-4e0c-9805-cb923ccbbf21',
        )
        print("âœ… ModelScope Qwen æ¨¡å‹åˆå§‹åŒ–æˆåŠŸã€‚")
    except Exception as modelscope_error:
        print(f"âš ï¸ ModelScope æ¨¡å‹ä¸å¯ç”¨: {modelscope_error}")
        print("ğŸ”„ å›é€€åˆ° OpenAI æ¨¡å‹...")
        
        # å›é€€åˆ° OpenAI æ¨¡å‹
        model = ModelFactory.create(
            model_platform=ModelPlatformType.OPENAI,
            model_type=ModelType.GPT_4_1,
            url=config.OPENAI_API_URL,
            api_key=config.OPENAI_API_KEY,
        )
        print("âœ… OpenAI æ¨¡å‹åˆå§‹åŒ–æˆåŠŸã€‚")
except Exception as e:
    print(f"âŒ æ‰€æœ‰æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
    model = None

# åˆå§‹åŒ–æ ¸å¿ƒçš„ä¸¤ä¸ªAgent
print("ğŸ¤– æ­£åœ¨åŠ è½½AI Agents...")
market_monitor = MarketMonitorAgent(model) if model else None
agent_manager = AgentManager()
print("âœ… AI Agents å·²åŠ è½½ã€‚")


# --- æµå¼å“åº”è¾…åŠ©å·¥å…· ---
class StreamToQueue:
    """ä¸€ä¸ªè¾…åŠ©ç±»ï¼Œå°†æ ‡å‡†è¾“å‡ºé‡å®šå‘åˆ°é˜Ÿåˆ—ï¼Œç”¨äºæ•è·Agentçš„æ‰“å°è¾“å‡ºã€‚"""
    def __init__(self, q):
        self.q = q
    
    def write(self, msg):
        if msg:
            self.q.put(msg)
    
    def flush(self):
        pass

def stream_agent_response(agent_instance, user_message):
    """
    é€šç”¨å‡½æ•°ï¼Œç”¨äºæ‰§è¡ŒAgentå¹¶æµå¼è¿”å›å…¶å“åº”ã€‚
    å®ƒé€šè¿‡é‡å®šå‘stdoutæ¥æ•è·å¹¶æµå¼ä¼ è¾“CAMEL-AIåº“ä¸­çš„æ‰“å°ä¿¡æ¯ã€‚
    """
    q = queue.Queue()
    
    def worker():
        original_stdout = sys.stdout
        sys.stdout = StreamToQueue(q)
        try:
            result = agent_instance.step(user_message)
            # æœ€ç»ˆçš„ return ç»“æœä¹Ÿæ”¾å…¥é˜Ÿåˆ—
            q.put(result.msgs[0].content if result and result.msgs else "æœªèƒ½è·å–å“åº”")
        except Exception as e:
            error_msg = f"--- AGENT_EXECUTION_ERROR ---\nå¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {e}"
            print(error_msg)
        finally:
            sys.stdout = original_stdout
            q.put(None)  # ä½¿ç”¨ None ä½œä¸ºæµç»“æŸçš„ä¿¡å·

    threading.Thread(target=worker).start()

    while True:
        chunk = q.get()
        if chunk is None:
            break
        yield f"{chunk}\n"

# --- API ç«¯ç‚¹å®šä¹‰ ---

@app.route("/")
def health_check():
    """åŸºç¡€çš„å¥åº·æ£€æŸ¥ç«¯ç‚¹ã€‚"""
    return jsonify({"status": "ok", "message": "PolyAgent server is running."})

@app.route("/config")
def get_app_config():
    """å‘å‰ç«¯æä¾›æœåŠ¡å™¨é…ç½®ä¿¡æ¯ã€‚"""
    return jsonify({
        "openai_api_configured": bool(config.OPENAI_API_KEY and "sk-" in config.OPENAI_API_KEY),
        "iotex_rpc_url": config.IOTEX_RPC_URL,
    })

@app.route("/agents/status")
def get_agents_status():
    """æ£€æŸ¥å¹¶è¿”å›æ‰€æœ‰æ ¸å¿ƒAgentçš„è¿è¡ŒçŠ¶æ€ã€‚"""
    return jsonify({
        "market_monitor": "ok" if market_monitor and model else "error",
        "agent_manager": "ok" if agent_manager else "error",
    })

@app.route("/market-monitor", methods=["POST"])
def handle_market_monitor():
    """å¤„ç†æ¥è‡ªå‰ç«¯çš„å¸‚åœºç›‘æ§è¯·æ±‚ã€‚"""
    data = request.json
    message = data.get("message")
    if not message:
        return jsonify({"error": "è¯·æ±‚ä½“ä¸­ç¼ºå°‘'message'å­—æ®µ"}), 400
    if not market_monitor:
         return jsonify({"error": "Market Monitor Agent æœªæˆåŠŸåˆå§‹åŒ–"}), 500

    def stream_monitor_response():
        """ä¸“é—¨ä¸º MarketMonitorAgent è®¾è®¡çš„æµå¼å“åº”ç”Ÿæˆå™¨ã€‚"""
        q = queue.Queue()
        
        def worker():
            original_stdout = sys.stdout
            sys.stdout = StreamToQueue(q)
            try:
                # MarketMonitorAgent ä½¿ç”¨ 'run' æ–¹æ³•å¹¶ç›´æ¥è¿”å›å­—ç¬¦ä¸²
                result = market_monitor.run(message)
                q.put(result)
            except Exception as e:
                error_msg = f"--- AGENT_EXECUTION_ERROR ---\nå¤„ç† Market Monitor è¯·æ±‚æ—¶å‡ºé”™: {e}"
                print(error_msg)
            finally:
                sys.stdout = original_stdout
                q.put(None)  # æµç»“æŸä¿¡å·

        threading.Thread(target=worker).start()

        while True:
            chunk = q.get()
            if chunk is None:
                break
            yield f"{chunk}\n"

    return Response(stream_with_context(stream_monitor_response()), mimetype="text/plain")

@app.route("/market-trade", methods=["POST"])
def handle_market_trade():
    """å¤„ç†æ¥è‡ªå‰ç«¯çš„è·¨å¢ƒæ”¯ä»˜æ¡¥æ¥è¯·æ±‚"""
    data = request.json
    message = data.get("message")
    if not message:
        return jsonify({"error": "è¯·æ±‚ä½“ä¸­ç¼ºå°‘'message'å­—æ®µ"}), 400
    if not agent_manager:
        return jsonify({"error": "Agent Manager æœªæˆåŠŸåˆå§‹åŒ–"}), 500
        
    def stream_agent_response():
        q = queue.Queue()
        
        def worker():
            original_stdout = sys.stdout
            sys.stdout = StreamToQueue(q)
            try:
                # ä½¿ç”¨æ–°çš„æ™ºèƒ½è·¯ç”±ç³»ç»Ÿå¤„ç†ç”¨æˆ·æ¶ˆæ¯
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                result = loop.run_until_complete(agent_manager.smart_route_request(message))
                loop.close()
                
                # ç›´æ¥è¾“å‡ºç»“æœ
                if result:
                    q.put(result)
                else:
                    q.put("Unable to process your request. Please try again.")
                        
            except Exception as e:
                error_msg = f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {e}"
                q.put(error_msg)
            finally:
                sys.stdout = original_stdout
                q.put(None)  # ä½¿ç”¨ None ä½œä¸ºæµç»“æŸçš„ä¿¡å·

        threading.Thread(target=worker).start()

        while True:
            chunk = q.get()
            if chunk is None:
                break
            yield f"{chunk}\n"
    
    return Response(stream_with_context(stream_agent_response()), mimetype="text/plain")

@app.route("/download/<filename>")
def download_file(filename):
    """æä¾›æ–‡ä»¶ä¸‹è½½æœåŠ¡"""
    try:
        file_path = os.path.join("downloads", filename)
        if os.path.exists(file_path):
            return send_file(file_path, as_attachment=True, download_name=filename)
        else:
            return jsonify({"error": "æ–‡ä»¶ä¸å­˜åœ¨"}), 404
    except Exception as e:
        return jsonify({"error": f"ä¸‹è½½å¤±è´¥: {str(e)}"}), 500

# --- æœåŠ¡å™¨å¯åŠ¨ ---
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸš€ å¯åŠ¨ PolyAgent æœåŠ¡å™¨...")
    if not (config.OPENAI_API_KEY and "sk-" in config.OPENAI_API_KEY):
        print("âš ï¸ è­¦å‘Š: OpenAI API å¯†é’¥æœªé…ç½®æˆ–æ ¼å¼ä¸æ­£ç¡®ã€‚")
        print("   è¯·åœ¨ `AgentCore/config.py` æˆ–ç¯å¢ƒå˜é‡ä¸­è®¾ç½® `OPENAI_API_KEY`ã€‚")
    
    print(f"ğŸ”— æœåŠ¡åœ°å€: http://{config.FLASK_HOST}:{config.FLASK_PORT}")
    print(f"ğŸ”§ è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if config.FLASK_DEBUG else 'å…³é—­'}")
    print("=" * 60)
    
    # ä½¿ç”¨ gunicorn å¯åŠ¨æ—¶ï¼Œä¸ä¼šæ‰§è¡Œè¿™é‡Œçš„ app.run
    # ç›´æ¥è¿è¡Œ `python app.py` æ—¶ä¼šä½¿ç”¨ Flask çš„å¼€å‘æœåŠ¡å™¨
    app.run(host=config.FLASK_HOST, port=config.FLASK_PORT, debug=config.FLASK_DEBUG) 